#!/usr/local/bin/perl -w

use strict;

use Carp;
use FileHandle;
use Math::Complex;

############################################################
## Program Defaults and Global Variables
############################################################

my $DIR  = "../hw3";
my $HOME = ".";

my $tank_token_docs = "$DIR/tank";           # tokenized tank journals
my $tank_corps_freq = "$DIR/tank";           # frequency of each token in tank.
my $plant_token_docs = "$DIR/plant";
my $plant_corps_freq = "$DIR/plant";
my $perplace_token_docs = "$DIR/perplace";
my $perplace_corps_freq = "$DIR/perplace";

my $stoplist   = "$DIR/common_words";   # common uninteresting words
my $tank_titles     = "$DIR/tank.titles";   # titles of each article in tank 
my $plant_titles     = "$DIR/plant.titles";
my $perplace_titles     = "$DIR/plant.titles";

my $token_docs	= ();		
my $titles		= ();	
my $doc_freq	= ();

my $num_doc_total = 4000;
my $num_doc_1 = 0;
my $num_doc_2 = 0;
my $num_doc_test = 400;
my $num_doc_train = $num_doc_total - $num_doc_test;

my @doc_type = ();

# the weight of document
my @doc_weight = ();

# the average vecter of set 1 and 
my @doc_average_1 = ();
my @doc_average_2 = ();	

my %doc_freq_hash = ();

my @doc_title = ();

# @doc_vector
#
#   An array of hashes, each array index indicating a particular noun document's
#   weight "vector". 

my @tank_doc_vector = ( );

my @plant_doc_vector = ( );

my @perplace_doc_vector = ( );

# @doc_vector_array_1
#
#   An array stores all the particular documents that the 
#	last element equal to 1

my %tank_vector_profile_1 = ( );

my %plant_vector_profile_1 = ( );

my %perplace_vector_profile_1 = ( );

my %tank_sum_1 = ( );

my %plant_sum_1 = ( );

my %perplace_sum_1 = ( );

# @doc_vector_array_2
#
#   An array stores all the particular documents that the 
#	last element equal to 2

my %tank_vector_profile_2 = ( );

my %plant_vector_profile_2 = ( );

my %perplace_vector_profile_2 = ( );

my %tank_sum_2 = ( );

my %plant_sum_2 = ( );

my %perplace_sum_2 = ( );

# @titles_vector
#
# vector of the cacm journal titles. Indexed in order of apperance
# within the corpus.

my @tank_titles_vector = ( );

my @plant_titles_vector = ( );

my @perplace_titles_vector = ( );

# %relevance_hash
#
# a hash of hashes where each <key, value> pair consists of
#
#   key   = a query number
#   value = a hash consisting of document number keys with associated
#           numeric values indicating the degree of relevance the 
#           document has to the particular query.

my %relevance_hash = ( );

# @doc_simula
#
# array used for storing query to document or document to document
# similarity calculations (determined by cosine_similarity, etc. )

my @doc_simula = ( );

# @qry_vector

#   An array of hashes, each array index indicating a particular query's
#   weight "vector".

my @res_vector = ( );

# %docs_freq_hash
#
# associative array which holds <token, frequency> pairs where
#
#   token     = a particular word or tag found in the cacm corpus
#   frequency = the total number of times the token appears in
#               the corpus.

my %tank_docs_freq_hash = ( );  

my %plant_docs_freq_hash = ( ); 

my %perplace_docs_freq_hash = ( );    

# %corp_freq_hash
#
# associative array which holds <token, frequency> pairs where
#
#   token     = a particular word or tag found in the corpus
#   frequency = the total number of times the token appears per
#               document-- that is a token is counted only once
#               per document if it is present (even if it appears 
#               several times within that document).

my %tank_corp_freq_hash = ( );

my %plant_corp_freq_hash = ( );

my %perplace_corp_freq_hash = ( );

# %stoplist_hash
#
# common list of uninteresting words which are likely irrelvant
# to any query.
#
#   Note: this is an associative array to provide fast lookups
#         of these boring words

my %stoplist_hash  = ( );


my @result_array = ( );

my @tank_sensenum = ( );

my @plant_sensenum = ( );

my @perplace_sensenum = ( );

my $tank_doc_num = 0;

my $plant_doc_num = 0;

my $perplace_doc_num = 0;

# Variable counts the correct / incorrect results.

my $tank_total_correct = 0;

my $tank_total_incorrect = 0;

my $plant_total_correct = 0;

my $plant_total_incorrect = 0;

my $perplace_total_correct = 0;

my $perplace_total_incorrect = 0;

my %tank_LLike = ( );

my %plant_LLike = ( );

my %perplace_LLike = ( );

my %v_test = ( );


&main_loop;

sub init_files {

	$tank_token_docs = "$DIR/tank";
	$tank_corps_freq = "$DIR/tank";
	$plant_token_docs = "$DIR/plant";
	$plant_corps_freq = "$DIR/plant";
	$perplace_token_docs = "$DIR/perplace";
	$perplace_corps_freq = "$DIR/perplace";
	$stoplist   = "$DIR/common_words";

    if ("stemmed" eq (shift || "")) {
		$tank_token_docs .= "\.stemmed";
		$tank_corps_freq .= "\.stemmed\.hist";
		$plant_token_docs .= "\.stemmed";
		$plant_corps_freq .= "\.stemmed\.hist";
		$perplace_token_docs .= "\.stemmed";
		$perplace_corps_freq .= "\.stemmed\.hist";
		$stoplist   .= "\.stemmed";
    }
    else {
		$tank_token_docs .= "\.tokenized";
		$tank_corps_freq .= "\.tokenized\.hist";
		$plant_token_docs .= "\.tokenized";
		$plant_corps_freq .= "\.tokenized\.hist";
		$perplace_token_docs .= "\.tokenized";
		$perplace_corps_freq .= "\.tokenized\.hist";
    }
}

sub init_evaluation_files {

	$token_docs	= ();	# tokenized cacm journals
	$stoplist	= ();	# common uninteresting words
	$titles		= ();	# titles of each article in cacm
	$doc_freq	= ();	# the number of documents contain a word

   	my $fileName = shift;

	if ("stemmed" eq (shift || "")) {
		$token_docs	= "$DIR/$fileName\.stemmed";
	}
	else {
		$token_docs	= "$DIR/$fileName\.tokenized";
	}
	
	$stoplist	= "$DIR/common_words";
	$titles		= "$DIR/$fileName\.titles";
	$doc_freq	= "$token_docs\.hist";
}

##########################################################
##  INIT_CORP_FREQ 
##
##  This function reads in corpus and document frequencies from
##  the provided histogram file for both the document set
##  and the query set. This information will be used in
##  term weighting.
##
##  It also initializes the arrays representing the stoplist,
##  title list and relevance of document given query.
##########################################################

sub init_corp_freq {

    my $tank_corps_freq_fh = new FileHandle $tank_corps_freq, "r" 
	or croak "Failed $tank_corps_freq";

	my $plant_corps_freq_fh = new FileHandle $plant_corps_freq, "r" 
	or croak "Failed $plant_corps_freq";

	my $perplace_corps_freq_fh = new FileHandle $perplace_corps_freq, "r" 
	or croak "Failed $perplace_corps_freq";

    my $stoplist_fh = new FileHandle $stoplist  , "r"
	or croak "Failed $stoplist";

    my $tank_titles_fh = new FileHandle $tank_titles    , "r"
	or croak "Failed $tank_titles";

	my $plant_titles_fh = new FileHandle $plant_titles    , "r"
	or croak "Failed $plant_titles";

	my $perplace_titles_fh = new FileHandle $perplace_titles    , "r"
	or croak "Failed $perplace_titles";

    my $line = undef;

    while (defined( $line = <$tank_corps_freq_fh> )) {

	# so on my computer split will return a first element of undef 
	# if the leading characters are white space, so I eat the white
	# space to insure that the split works right.

		my ($str) = ($line =~ /^\s*(\S.*)/);

		my ($doc_freq,
		    $cor_freq, 
		    $term    ) = split /\s+/, $str;

		$tank_docs_freq_hash{ $term } = $doc_freq;
		$tank_corp_freq_hash{ $term } = $cor_freq;
    }

    while (defined( $line = <$plant_corps_freq_fh> )) {

	# so on my computer split will return a first element of undef 
	# if the leading characters are white space, so I eat the white
	# space to insure that the split works right.

		my ($str) = ($line =~ /^\s*(\S.*)/);

		my ($doc_freq,
		    $cor_freq, 
		    $term    ) = split /\s+/, $str;

		$plant_docs_freq_hash{ $term } = $doc_freq;
		$plant_corp_freq_hash{ $term } = $cor_freq;
    }

    while (defined( $line = <$perplace_corps_freq_fh> )) {

	# so on my computer split will return a first element of undef 
	# if the leading characters are white space, so I eat the white
	# space to insure that the split works right.

		my ($str) = ($line =~ /^\s*(\S.*)/);

		my ($doc_freq,
		    $cor_freq, 
		    $term    ) = split /\s+/, $str;

		$perplace_docs_freq_hash{ $term } = $doc_freq;
		$perplace_corp_freq_hash{ $term } = $cor_freq;
    }

    while (defined( $line = <$stoplist_fh> )) {

		chomp $line;
		$stoplist_hash{ $line } = 1;
    }


    push @tank_titles_vector, "";       # push one empty value onto @titles_vector
    push @plant_titles_vector, ""; 
    push @perplace_titles_vector, ""; 
                                   # so that indices correspond with title
                                   # numbers.

    while (defined( $line = <$tank_titles_fh> )) {

		chomp $line;
		push @tank_titles_vector, $line;
    }

    while (defined( $line = <$plant_titles_fh> )) {

		chomp $line;
		push @plant_titles_vector, $line;
    }

    while (defined( $line = <$perplace_titles_fh> )) {

		chomp $line;
		push @perplace_titles_vector, $line;
    }

}

sub init_evaluation_title_freq {
	%stoplist_hash	= ();
	@doc_title		= ();
	
	my $stoplist_fh	= new FileHandle $stoplist	, "r"
		or croak "Failed $stoplist";
	my $titles_fh	= new FileHandle $titles	, "r"
		or croak "Failed $titles";
	my $doc_freq_fh	= new FileHandle $doc_freq	, "r"
		or croak "Failed $doc_freq";

	my $line = undef;
	
	# common words
	if (shift ne "all") {
		while (defined($line = <$stoplist_fh>)) {
			chomp $line;
			$stoplist_hash{$line} = 1;
		}
	}
	
	# title
	push @doc_title, "";       
	while (defined($line = <$titles_fh>)) {
		chomp $line;
		push @doc_title, $line;
	}
	
	# document frequncy
	while (defined($line = <$doc_freq_fh>)) {
		my ($str) = ($line =~ /^\s*(\S.*)/);
		
		my ($doc, $cor, $term) = split /\s+/, $str;
		$doc_freq_hash{$term} = $doc;
	}
}

sub init {
	
	&init_evaluation_files(shift, shift);
	&init_evaluation_title_freq(shift);
	&init_evaluation_doc_vectors(shift, shift);
}

sub init_doc_vectors {

	@tank_sensenum = ( );
	@plant_sensenum = ( );
	@perplace_sensenum = ( );

    my $tank_token_docs_fh = new FileHandle $tank_token_docs, "r"
	or croak "Failed $tank_token_docs";

	push(@tank_sensenum, 5);

    push @tank_doc_vector, { };     # push one empty value onto @doc_noun_vector so that

	my $plant_token_docs_fh = new FileHandle $plant_token_docs, "r"
	or croak "Failed $plant_token_docs";

	push(@plant_sensenum, 5);
	push @plant_doc_vector, { };

	my $perplace_token_docs_fh = new FileHandle $perplace_token_docs, "r"
	or croak "Failed $perplace_token_docs";

	push(@perplace_sensenum, 5);
	push @perplace_doc_vector, { };

	# my $plant_token_docs_fh = new FileHandle $plant_token_docs_fh, "r"
	# or croak "Failed $plant_token_docs";

    my $word = undef;

    $tank_doc_num =  0;    # current document number and total docs at end
    $plant_doc_num = 0;
    $perplace_doc_num = 0;

    my $tweight =  1;    # current weight assigned to document token

    my @split_array = ( );

    
                               # indices correspond with document numbers
    %tank_vector_profile_1 = ( );
   	%tank_vector_profile_2 = ( );
   	%plant_vector_profile_1 = ( );
   	%plant_vector_profile_2 = ( );
   	%perplace_vector_profile_1 = ( );
   	%perplace_vector_profile_2 = ( );

    while (defined( $word = <$tank_token_docs_fh> )) {
	
		chomp $word;

		#last if $word =~ /^\.I 0/; # indicates end of file so kick out
		
		if ($word =~ /^\.I/) {     # indicates start of a new document
			
			@split_array = split(/ /, $word);
		    push (@tank_sensenum, $split_array[2]);
		    push @tank_doc_vector, { };
		    $tank_doc_num++;
		  
		    next;
		}

		if ($word =~ /[a-zA-Z]/ and ! exists $stoplist_hash{ $word }) {
			
		    if (defined( $tank_docs_freq_hash{ $word } )) {

		    	$tank_doc_vector[$tank_doc_num]{ $word } += $tweight;

		    	if ($tank_sensenum[$tank_doc_num] == 1 and $tank_doc_num <= 3600) {
					$tank_vector_profile_1{$tank_doc_num}{ $word } += $tweight;
				}

				if ($tank_sensenum[$tank_doc_num] == 2 and $tank_doc_num <= 3600) {
					$tank_vector_profile_2{$tank_doc_num}{ $word } += $tweight;
				}
		    }
		    else {
				print "ERROR: Document frequency of zero: ", $word, "\n";
		    }
		}
    }

    while (defined( $word = <$plant_token_docs_fh> )) {
	
		chomp $word;

		#last if $word =~ /^\.I 0/; # indicates end of file so kick out
		
		if ($word =~ /^\.I/) {     # indicates start of a new document
			
			@split_array = split(/ /, $word);
		    push (@plant_sensenum, $split_array[2]);
		    push @plant_doc_vector, { };
		    $plant_doc_num++;
		  
		    next;
		}

		if ($word =~ /[a-zA-Z]/ and ! exists $stoplist_hash{ $word }) {
			
		    if (defined( $plant_docs_freq_hash{ $word } )) {

		    	$plant_doc_vector[$plant_doc_num]{ $word } += $tweight;

		    	if ($plant_sensenum[$plant_doc_num] == 1 and $plant_doc_num <= 3600) {
					$plant_vector_profile_1{$plant_doc_num}{ $word } += $tweight;
				}

				if ($plant_sensenum[$plant_doc_num] == 2 and $plant_doc_num <= 3600) {
					$plant_vector_profile_2{$plant_doc_num}{ $word } += $tweight;
				}
		    }
		    else {
				print "ERROR: Document frequency of zero: ", $word, "\n";
		    }
		}
    }

    while (defined( $word = <$perplace_token_docs_fh> )) {
	
		chomp $word;

		#last if $word =~ /^\.I 0/; # indicates end of file so kick out
		
		if ($word =~ /^\.I/) {     # indicates start of a new document
			
			@split_array = split(/ /, $word);
		    push (@perplace_sensenum, $split_array[2]);
		    push @perplace_doc_vector, { };
		    $perplace_doc_num++;
		  
		    next;
		}

		if ($word =~ /[a-zA-Z]/ and ! exists $stoplist_hash{ $word }) {
			
		    if (defined( $perplace_docs_freq_hash{ $word } )) {

		    	$perplace_doc_vector[$perplace_doc_num]{ $word } += $tweight;

		    	if ($perplace_sensenum[$perplace_doc_num] == 1 and $perplace_doc_num <= 3600) {
					$perplace_vector_profile_1{$perplace_doc_num}{ $word } += $tweight;
				}

				if ($perplace_sensenum[$perplace_doc_num] == 2 and $perplace_doc_num <= 3600) {
					$perplace_vector_profile_2{$perplace_doc_num}{ $word } += $tweight;
				}
		    }
		    else {
				print "ERROR: Document frequency of zero: ", $word, "\n";
		    }
		}
    }

}


###################################################
# For extension
# Init do vectors
###################################################

sub init_bayesian_doc_vectors {

	@tank_sensenum = ( );
	@plant_sensenum = ( );
	@perplace_sensenum = ( );

    my $tank_token_docs_fh = new FileHandle $tank_token_docs, "r"
	or croak "Failed $tank_token_docs";

	push(@tank_sensenum, 5);

    push @tank_doc_vector, { };     # push one empty value onto @doc_noun_vector so that

	my $plant_token_docs_fh = new FileHandle $plant_token_docs, "r"
	or croak "Failed $plant_token_docs";

	push(@plant_sensenum, 5);
	push @plant_doc_vector, { };

	my $perplace_token_docs_fh = new FileHandle $perplace_token_docs, "r"
	or croak "Failed $perplace_token_docs";

	push(@perplace_sensenum, 5);
	push @perplace_doc_vector, { };

	# my $plant_token_docs_fh = new FileHandle $plant_token_docs_fh, "r"
	# or croak "Failed $plant_token_docs";

    my $word = undef;

    $tank_doc_num =  0;    # current document number and total docs at end
    $plant_doc_num = 0;
    $perplace_doc_num = 0;

    my $tweight =  1;    # current weight assigned to document token

    my @split_array = ( );

    
                               # indices correspond with document numbers
    %tank_sum_1 = ( );
   	%tank_sum_2 = ( );
   	%plant_sum_1 = ( );
   	%plant_sum_2 = ( );
   	%perplace_sum_1 = ( );
   	%perplace_sum_2 = ( );

    while (defined( $word = <$tank_token_docs_fh> )) {
	
		chomp $word;

		#last if $word =~ /^\.I 0/; # indicates end of file so kick out
		
		if ($word =~ /^\.I/) {     # indicates start of a new document
			
			@split_array = split(/ /, $word);
		    push (@tank_sensenum, $split_array[2]);
		    push @tank_doc_vector, { };
		    $tank_doc_num++;
		  
		    next;
		}

		if ($word =~ /[a-zA-Z]/ and ! exists $stoplist_hash{ $word }) {
			
		    if (defined( $tank_docs_freq_hash{ $word } )) {

		    	$tank_doc_vector[$tank_doc_num]{ $word } += $tweight;

		    	if ($tank_sensenum[$tank_doc_num] == 1 and $tank_doc_num <= 3600) {
					$tank_sum_1{$tank_doc_num}{ $word } += $tweight;
				}

				if ($tank_sensenum[$tank_doc_num] == 2 and $tank_doc_num <= 3600) {
					$tank_sum_2{$tank_doc_num}{ $word } += $tweight;
				}
		    }
		    else {
				print "ERROR: Document frequency of zero: ", $word, "\n";
		    }
		}
    }

    while (defined( $word = <$plant_token_docs_fh> )) {
	
		chomp $word;

		#last if $word =~ /^\.I 0/; # indicates end of file so kick out
		
		if ($word =~ /^\.I/) {     # indicates start of a new document
			
			@split_array = split(/ /, $word);
		    push (@plant_sensenum, $split_array[2]);
		    push @plant_doc_vector, { };
		    $plant_doc_num++;
		  
		    next;
		}

		if ($word =~ /[a-zA-Z]/ and ! exists $stoplist_hash{ $word }) {
			
		    if (defined( $plant_docs_freq_hash{ $word } )) {

		    	$plant_doc_vector[$plant_doc_num]{ $word } += $tweight;

		    	if ($plant_sensenum[$plant_doc_num] == 1 and $plant_doc_num <= 3600) {
					$plant_sum_1{$plant_doc_num}{ $word } += $tweight;
				}

				if ($plant_sensenum[$plant_doc_num] == 2 and $plant_doc_num <= 3600) {
					$plant_sum_2{$plant_doc_num}{ $word } += $tweight;
				}
		    }
		    else {
				print "ERROR: Document frequency of zero: ", $word, "\n";
		    }
		}
    }

    while (defined( $word = <$perplace_token_docs_fh> )) {
	
		chomp $word;

		#last if $word =~ /^\.I 0/; # indicates end of file so kick out
		
		if ($word =~ /^\.I/) {     # indicates start of a new document
			
			@split_array = split(/ /, $word);
		    push (@perplace_sensenum, $split_array[2]);
		    push @perplace_doc_vector, { };
		    $perplace_doc_num++;
		  
		    next;
		}

		if ($word =~ /[a-zA-Z]/ and ! exists $stoplist_hash{ $word }) {
			
		    if (defined( $perplace_docs_freq_hash{ $word } )) {

		    	$perplace_doc_vector[$perplace_doc_num]{ $word } += $tweight;

		    	if ($perplace_sensenum[$perplace_doc_num] == 1 and $perplace_doc_num <= 3600) {
					$perplace_sum_1{$perplace_doc_num}{ $word } += $tweight;
				}

				if ($perplace_sensenum[$perplace_doc_num] == 2 and $perplace_doc_num <= 3600) {
					$perplace_sum_2{$perplace_doc_num}{ $word } += $tweight;
				}
		    }
		    else {
				print "ERROR: Document frequency of zero: ", $word, "\n";
		    }
		}
    }

}

sub init_evaluation_doc_vectors {

	my $type = shift;
	my $bag_word = shift;
	my $token_docs_fh = new FileHandle $token_docs, "r"
		or croak "Failed $token_docs";

	my $word = undef;
	# the words in one document
	my @doc = ();
	# the position of .X
	my $position = -1;

	# push one empty value onto @doc_vector so that
	# indices correspond with document numbers
	@doc_weight = ();
	@doc_type = ();
	push @doc_weight, {}; 
	push @doc_type, {}; 
	
	my $i = 0;
	while (defined($word = <$token_docs_fh>)) {
		chomp $word;
		
		# indicates start of a new document
		if ($word =~ /^\.I/) {
			if ($i != 0) {
				if ($bag_word eq "LR") {
					if ($position >= 2) {
						$doc[$position-1] = "L-$doc[$position-1]";
					}
					if ($position <= scalar @doc-2) {
						$doc[$position+1] = "R-$doc[$position+1]";
					}
				}
				my $j = 0;
				for ($j = 1; $j < scalar @doc; $j++) {
					my $dis = abs($j-$position);
					if ($j != $position) {
						if ($type eq "uniform") {
							$doc_weight[$i]{$doc[$j]} += 1;
						}
						elsif ($type eq "expndecay") {
							$doc_weight[$i]{$doc[$j]} += 1/$dis;
						}
						elsif ($type eq "stepped") {
							if ($dis <= 1) {
								$doc_weight[$i]{$doc[$j]} += 6;
							}
							elsif ($dis <= 3) {
								$doc_weight[$i]{$doc[$j]} += 3;
							}
							else {
								$doc_weight[$i]{$doc[$j]} += 1;
							}
						}
						elsif ($type eq "yours") {
							my $temp = $doc[$j];
							if ($temp =~ /^L-/ || $temp =~ /^R-/) {
								$temp = substr($doc[$j], 2);
							}
							my $weight = 1;
							if ($doc_freq_hash{$temp}) {
								$weight = log($num_doc_total/$doc_freq_hash{$temp});
							}
							$doc_weight[$i]{$doc[$j]} += 1/$dis*$weight;
						}
					}
				}
			}
			$i ++;
			# indicates the type of new document 
			push @doc_weight, {};
			if ($word =~ /1$/) {
				push @doc_type, 1;
				if ($i <= $num_doc_train) {
					$num_doc_1 ++;
				}
			}
			else {
				push @doc_type, 2;
				if ($i <= $num_doc_train) {
					$num_doc_2 ++;
				}
			}
			@doc = ();
			push @doc, {};
		}
		elsif (($word eq "</S>" || $word eq "<S>")) {
			next;
		}
		elsif (!$stoplist_hash{$word}) {
			push @doc, $word;
			if ($word =~ /^\.X/ || $word =~ /^\.x/) {
				$position = scalar @doc - 1;
			}
		}
	}
}

sub main_loop {

	print "INITIALIZING VECTORS ... \n";

    &init_files ( "stemmed" );
    &init_corp_freq;

    &init_doc_vectors;

     while (1) {

     	@tank_doc_vector = ( );
     	%tank_docs_freq_hash = ( ); 
 		%tank_corp_freq_hash = ( );
 		%stoplist_hash  = ( );
 		@tank_titles_vector  = ( );
 		%relevance_hash = ( );
 		@doc_simula = ( );
 		@res_vector = ( );
 		%tank_vector_profile_1 = ( );
 		%tank_vector_profile_2 = ( );
 		%tank_sum_1 = ( );
 		%tank_sum_2 = ( );

 		@plant_doc_vector = ( );
     	%plant_docs_freq_hash = ( ); 
 		%plant_corp_freq_hash = ( );
 		@plant_titles_vector  = ( );
 		%plant_vector_profile_1 = ( );
 		%plant_vector_profile_2 = ( );
 		%plant_sum_1 = ( );
 		%plant_sum_2 = ( );

 		@perplace_doc_vector = ( );
     	%perplace_docs_freq_hash = ( ); 
 		%perplace_corp_freq_hash = ( );
 		@perplace_titles_vector  = ( );
 		%perplace_vector_profile_1 = ( );
 		%perplace_vector_profile_2 = ( );
 		%perplace_sum_1 = ( );
 		%perplace_sum_2 = ( );
     

	    print <<"EndOfMenu";

	============================================================
	==     Welcome to the 600.466 Lexical Ambiguity IR Engine
	==                                                  
        == Total Documents: $num_doc_total                     
	==                      
	============================================================

	OPTIONS:
	  1 = Part 1 - Uniform stemmed correctness
	  2 = Part 2 & 3 - Evaluation
	  3 = Extension - Baysian model based on Simple TF
	  4 = Quit

	============================================================

EndOfMenu
	    ;

	    print "Enter Option: ";

		my    $option = <STDIN>;
		chomp $option;

		@result_array = ( );

		exit 0 if $option == 4;

		if ($option == 1) {
			&init_files ( "stemmed" );
			&init_corp_freq;
			&init_doc_vectors;
			&permutation();
			&normalization();
    		&centroid();
    		&cosine_similarity();			
		}

		if ($option == 2) {
			&evaluation();
		}

		if ($option == 3) {
			&init_files( "stemmed" );
			&init_corp_freq;
			&init_bayesian_doc_vectors;
			&bayesian_normalization();
    		&centroid();
    		&bayesian_similarity();
		}

	}
}

##########################################################
##  The permutation type is TF-IDF
##########################################################

sub permutation {

	my $i = 0;

    foreach my $hash (@tank_doc_vector) {

    	foreach my $key (keys %{ $hash }) {

            $hash->{ $key } = ($hash->{ $key } * log($tank_doc_num / $tank_docs_freq_hash{ $key }));

            if($tank_sensenum[$i] == 1 and $i <= 3600) {

    			$tank_vector_profile_1{$i}{ $key } = $hash->{ $key };

    		}
    		if($tank_sensenum[$i] == 2 and $i <= 3600) {

    			$tank_vector_profile_2{$i}{ $key } = $hash->{ $key };
    			
    		}
        }
        $i++;

    }
    $i = 0;

    foreach my $hash (@plant_doc_vector) {

    	foreach my $key (keys %{ $hash }) {

            $hash->{ $key } = ($hash->{ $key } * log($plant_doc_num / $plant_docs_freq_hash{ $key }));

            if($plant_sensenum[$i] == 1 and $i <= 3600) {

    			$plant_vector_profile_1{$i}{ $key } = $hash->{ $key };

    		}
    		if($plant_sensenum[$i] == 2 and $i <= 3600) {

    			$plant_vector_profile_2{$i}{ $key } = $hash->{ $key };
    			
    		}
        }
        $i++;

    }
    $i = 0;

    foreach my $hash (@perplace_doc_vector) {

    	foreach my $key (keys %{ $hash }) {

            $hash->{ $key } = ($hash->{ $key } * log($perplace_doc_num / $perplace_docs_freq_hash{ $key }));

            if($perplace_sensenum[$i] == 1 and $i <= 3600) {

    			$perplace_vector_profile_1{$i}{ $key } = $hash->{ $key };

    		}
    		if($perplace_sensenum[$i] == 2 and $i <= 3600) {

    			$perplace_vector_profile_2{$i}{ $key } = $hash->{ $key };
    			
    		}
        }
        $i++;

    }
    $i = 0;

}


sub normalization {

	my $weight_sum = 0;

	my $i = 0;

    foreach my $hash (@tank_doc_vector) {

    	foreach my $index (keys %{ $hash }) {

    		$weight_sum += ($hash->{ $index } * $hash->{ $index }); 

    	}

    	foreach my $key (keys %{ $hash }) {

            $hash->{ $key } = $hash->{ $key } / sqrt($weight_sum);

            if($tank_sensenum[$i] == 1 and $i <= 3600) {

    			$tank_vector_profile_1{$i}{ $key } = $hash->{ $key };

    		}
    		if($tank_sensenum[$i] == 2 and $i <= 3600) {

    			$tank_vector_profile_2{$i}{ $key } = $hash->{ $key };
    			
    		}
        }
        $i++;
       
    }
    $i = 0;

    foreach my $hash (@plant_doc_vector) {

    	foreach my $index (keys %{ $hash }) {

    		$weight_sum += ($hash->{ $index } * $hash->{ $index }); 

    	}

    	foreach my $key (keys %{ $hash }) {

            $hash->{ $key } = $hash->{ $key } / sqrt($weight_sum);

            if($plant_sensenum[$i] == 1 and $i <= 3600) {

    			$plant_vector_profile_1{$i}{ $key } = $hash->{ $key };

    		}
    		if($plant_sensenum[$i] == 2 and $i <= 3600) {

    			$plant_vector_profile_2{$i}{ $key } = $hash->{ $key };
    			
    		}
        }

        $i++;
      
    }

    $i = 0;

   foreach my $hash (@perplace_doc_vector) {

    	foreach my $index (keys %{ $hash }) {

    		$weight_sum += ($hash->{ $index } * $hash->{ $index }); 

    	}

    	foreach my $key (keys %{ $hash }) {

            $hash->{ $key } = $hash->{ $key } / sqrt($weight_sum);

            if($perplace_sensenum[$i] == 1 and $i <= 3600) {

    			$perplace_vector_profile_1{$i}{ $key } = $hash->{ $key };

    		}
    		if($perplace_sensenum[$i] == 2 and $i <= 3600) {

    			$perplace_vector_profile_2{$i}{ $key } = $hash->{ $key };
    			
    		}
        }

        $i++;
       
    }
    $i = 0;
	
}

sub bayesian_normalization {

	my $weight_sum = 0;

	my $i = 0;

    foreach my $hash (@tank_doc_vector) {

    	foreach my $index (keys %{ $hash }) {

    		$weight_sum += ($hash->{ $index } * $hash->{ $index }); 

    	}

    	foreach my $key (keys %{ $hash }) {

            $hash->{ $key } = $hash->{ $key } / sqrt($weight_sum);

            if($tank_sensenum[$i] == 1 and $i <= 3600) {

    			$tank_sum_1{$i}{ $key } = $hash->{ $key };

    		}
    		if($tank_sensenum[$i] == 2 and $i <= 3600) {

    			$tank_sum_2{$i}{ $key } = $hash->{ $key };
    			
    		}
        }
        $i++;
       
    }
    $i = 0;

    foreach my $hash (@plant_doc_vector) {

    	foreach my $index (keys %{ $hash }) {

    		$weight_sum += ($hash->{ $index } * $hash->{ $index }); 

    	}

    	foreach my $key (keys %{ $hash }) {

            $hash->{ $key } = $hash->{ $key } / sqrt($weight_sum);

            if($plant_sensenum[$i] == 1 and $i <= 3600) {

    			$plant_sum_1{$i}{ $key } = $hash->{ $key };

    		}
    		if($plant_sensenum[$i] == 2 and $i <= 3600) {

    			$plant_sum_2{$i}{ $key } = $hash->{ $key };
    			
    		}
        }

        $i++;
      
    }

    $i = 0;

   foreach my $hash (@perplace_doc_vector) {

    	foreach my $index (keys %{ $hash }) {

    		$weight_sum += ($hash->{ $index } * $hash->{ $index }); 

    	}

    	foreach my $key (keys %{ $hash }) {

            $hash->{ $key } = $hash->{ $key } / sqrt($weight_sum);

            if($perplace_sensenum[$i] == 1 and $i <= 3600) {

    			$perplace_sum_1{$i}{ $key } = $hash->{ $key };

    		}
    		if($perplace_sensenum[$i] == 2 and $i <= 3600) {

    			$perplace_sum_2{$i}{ $key } = $hash->{ $key };
    			
    		}
        }

        $i++;
       
    }
    $i = 0;
	
}

sub centroid {

	my $tank_profile_num_1 = keys(%tank_vector_profile_1);
    my $tank_profile_num_2 = keys(%tank_vector_profile_2);

    my $tank_total_profile_weight_1 = 0;
    my $tank_total_profile_weight_2 = 0;

    my $plant_profile_num_1 = keys(%plant_vector_profile_1);
    my $plant_profile_num_2 = keys(%plant_vector_profile_2);

    my $plant_total_profile_weight_1 = 0;
    my $plant_total_profile_weight_2 = 0;

    my $perplace_profile_num_1 = keys(%perplace_vector_profile_1);
    my $perplace_profile_num_2 = keys(%perplace_vector_profile_2);

    my $perplace_total_profile_weight_1 = 0;
    my $perplace_total_profile_weight_2 = 0;

    foreach my $doc_num (keys %tank_vector_profile_1) {

    	while (my ($key, $value) = each %{$tank_vector_profile_1{ $doc_num } }) { 
    		
    		$tank_total_profile_weight_1 += $value;  	

    	}
    }

    while (my ($term, $weight) = each %tank_vector_profile_1) {

    	$tank_vector_profile_1{$term} = $weight / $tank_profile_num_1; 

    }

    foreach my $doc_num (keys %tank_vector_profile_2) {

    	while (my ($key, $value) = each %{$tank_vector_profile_2{ $doc_num } }) {
    		
    		$tank_total_profile_weight_2 += $value;

    	}
    }

    while (my ($term, $weight) = each %tank_vector_profile_2) {

    	$tank_vector_profile_2{$term} = $weight / $tank_profile_num_2; 

    }

    # plant
    foreach my $doc_num (keys %plant_vector_profile_1) {

    	while (my ($key, $value) = each %{$plant_vector_profile_1{ $doc_num } }) { 
    		
    		$plant_total_profile_weight_1 += $value; 

    	}
    }

    while (my ($term, $weight) = each %plant_vector_profile_1) {

    	$plant_vector_profile_1{$term} = $weight / $plant_profile_num_1;

    }

    foreach my $doc_num (keys %plant_vector_profile_2) {

    	while (my ($key, $value) = each %{$plant_vector_profile_2{ $doc_num } }) {
    		
    		$plant_total_profile_weight_2 += $value;

    	}
    }

    while (my ($term, $weight) = each %plant_vector_profile_2) {

    	$plant_vector_profile_2{$term} = $weight / $plant_profile_num_2;  

    }

    # perplace
    foreach my $doc_num (keys %perplace_vector_profile_1) {

    	while (my ($key, $value) = each %{$perplace_vector_profile_1{ $doc_num } }) { 
    		
    		$perplace_total_profile_weight_1 += $value;  	

    	}
    }

    while (my ($term, $weight) = each %perplace_vector_profile_1) {

    	$perplace_vector_profile_1{$term} = $weight / $perplace_profile_num_1;

    }

    foreach my $doc_num (keys %perplace_vector_profile_2) {

    	while (my ($key, $value) = each %{$perplace_vector_profile_2{ $doc_num } }) {
    		
    		$perplace_total_profile_weight_2 += $value;

    	}
    }

    while (my ($term, $weight) = each %perplace_vector_profile_2) {

    	$perplace_vector_profile_2{$term} = $weight / $perplace_profile_num_2;  

    }
}

sub bayesian_centroid {

    my $tank_total_profile_weight_1 = 0;
    my $tank_total_profile_weight_2 = 0;

    my $plant_total_profile_weight_1 = 0;
    my $plant_total_profile_weight_2 = 0;

    my $perplace_total_profile_weight_1 = 0;
    my $perplace_total_profile_weight_2 = 0;

    %tank_LLike = ( );

    foreach my $doc_num (keys %tank_sum_1) {
    	while (my ($key, $value) = each %{$tank_sum_1{ $doc_num } }) { 
    		$tank_total_profile_weight_1 += $value;  		
    	}
    }

    while (my ($term, $weight) = each %tank_sum_1) {
    	$tank_sum_1{$term} = $weight;   	
    }

    foreach my $doc_num (keys %tank_sum_2) {
    	while (my ($key, $value) = each %{$tank_sum_2{ $doc_num } }) {
    		$tank_total_profile_weight_2 += $value;
    	}
    }

    while (my ($term, $weight) = each %tank_sum_2) {
    	$tank_sum_2{$term} = $weight;   	
    }

    my $EPSILON = 0.2;
    
    while ( my ($term, $weight) = each %tank_sum_2) {

		if (tank_sum_1{$term} ) {
			$tank_LLike{$term} = log ( $tank_sum_1{$term} / $tank_sum_2{$term});
		}
		else {
			$tank_LLike{$term} = log ( $EPSILON / $tank_sum_2{$term});
		}
    }

    while (my ($term, $weight) = each %tank_sum_1) {
    	if ( !(tank_sum_2{$term}) ) {
    		$tank_LLike{$term} = log ($tank_LLike{$term} / $EPSILON);
    	} 	
    }

    
    # plant
    foreach my $doc_num (keys %plant_sum_1) {
    	while (my ($key, $value) = each %{$plant_sum_1{ $doc_num } }) { 
    		$plant_total_profile_weight_1 += $value;  		
    	}
    }

    while (my ($term, $weight) = each %plant_sum_1) {
    	$plant_sum_1{$term} = $weight;
    }

    foreach my $doc_num (keys %plant_sum_2) {
    	while (my ($key, $value) = each %{$plant_sum_2{ $doc_num } }) {
    		$plant_total_profile_weight_2 += $value;
    	}
    }

    while (my ($term, $weight) = each %plant_sum_2) {
    	$plant_sum_2{$term} = $weight;  	
    }

    while ( my ($term, $weight) = each %plant_sum_2) {
		if (plant_sum_1{$term} ) {
			$plant_LLike{$term} = log ( $plant_sum_1{$term} / $plant_sum_2{$term});
		}
		else {
			$plant_LLike{$term} = log ( $EPSILON / $plant_sum_2{$term});
		}
    }

    while (my ($term, $weight) = each %plant_sum_1) {
    	if ( !(plant_sum_2{$term}) ) {
    		$plant_LLike{$term} = log ($plant_LLike{$term} / $EPSILON);
    	} 	
    }

    # perplace
    foreach my $doc_num (keys %perplace_sum_1) {
    	while (my ($key, $value) = each %{$perplace_sum_1{ $doc_num } }) {  
    		$perplace_total_profile_weight_1 += $value;  		
    	}
    }

    while (my ($term, $weight) = each %perplace_sum_1) {
    	$perplace_sum_1{$term} = $weight;
    }

    foreach my $doc_num (keys %perplace_sum_2) {
    	while (my ($key, $value) = each %{$perplace_sum_2{ $doc_num } }) {
    		$perplace_total_profile_weight_2 += $value;
    	}
    }

    while (my ($term, $weight) = each %perplace_sum_2) {
    	$perplace_sum_2{$term} = $weight;   	
    }

    while ( my ($term, $weight) = each %perplace_sum_2) {
		if (perplace_sum_1{$term} ) {
			$perplace_LLike{$term} = log ( $perplace_sum_1{$term} / $perplace_sum_2{$term});
		}
		else {
			$perplace_LLike{$term} = log ( $EPSILON / $perplace_sum_2{$term});
		}
    }

    while (my ($term, $weight) = each %perplace_sum_1) {
    	if ( !(perplace_sum_2{$term}) ) {
    		$perplace_LLike{$term} = log ($perplace_LLike{$term} / $EPSILON);
    	} 	
    }

}

sub cosine_similarity {

	my $label = 0;

	$tank_total_correct = 0;
	$tank_total_incorrect = 0;

	$plant_total_correct = 0;
	$plant_total_incorrect = 0;

	for (3601 .. 4000) {
		my $sim1 = &cosine_sim_a(\%tank_vector_profile_1, $tank_doc_vector[$_]);
		my $sim2 = &cosine_sim_a(\%tank_vector_profile_2, $tank_doc_vector[$_]);

		if ($sim1 > $sim2) {
			$label = 1;
		}
		else {
			$label = 2;
		}

		my $print_sim1 = sprintf "%0.8f", $sim1;
		my $print_sim2 = sprintf "%0.8f", $sim2;

		if ($label == $tank_sensenum[$_]) {
			$tank_total_correct++;
			print substr ($tank_titles_vector[$_], 0, 70) . "\n";
		}
		else {
			$tank_total_incorrect++;
			print substr ($tank_titles_vector[$_], 0, 70) . "\n";
		}
	}

	print "Tank correctness is: ", $tank_total_correct / ($tank_total_correct + $tank_total_incorrect), "\n";

	$tank_total_correct = 0;
	$tank_total_incorrect = 0;

	for (3601 .. 4000) {
		my $sim1 = &cosine_sim_a(\%plant_vector_profile_1, $plant_doc_vector[$_]);
		my $sim2 = &cosine_sim_a(\%plant_vector_profile_2, $plant_doc_vector[$_]);

		if ($sim1 > $sim2) {
			$label = 1;
		}
		else {
			$label = 2;
		}

		my $print_sim1 = sprintf "%0.8f", $sim1;
		my $print_sim2 = sprintf "%0.8f", $sim2;

		if ($label == $plant_sensenum[$_]) {
			$plant_total_correct++;
		}
		else {
			$plant_total_incorrect++;
		}
	}
	print "Plant correctness is: ", $plant_total_correct / ($plant_total_correct + $plant_total_incorrect), "\n";

	$plant_total_correct = 0;
	$plant_total_incorrect = 0;

	for (3601 .. 4000) {
		my $sim1 = &cosine_sim_a(\%perplace_vector_profile_1, $perplace_doc_vector[$_]);
		my $sim2 = &cosine_sim_a(\%perplace_vector_profile_2, $perplace_doc_vector[$_]);

		if ($sim1 > $sim2) {
			$label = 1;
		}
		else {
			$label = 2;
		}

		my $print_sim1 = sprintf "%0.8f", $sim1;
		my $print_sim2 = sprintf "%0.8f", $sim2;

		if ($label == $perplace_sensenum[$_]) {
			$perplace_total_correct++;
		}
		else {
			$perplace_total_incorrect++;
		}
	}
	print "Perplace correctness is: ", $perplace_total_correct / ($perplace_total_correct + $perplace_total_incorrect), "\n";

	$perplace_total_correct = 0;
	$perplace_total_incorrect = 0;

}

sub bayesian_similarity {

	my $label = 0;
	my $sumofLL = 0;
	my $key = 0;

	$tank_total_correct = 0;
	$tank_total_incorrect = 0;

	$plant_total_correct = 0;
	$plant_total_incorrect = 0;

	foreach $key ( keys %tank_LLike ) {
		if ( tank_sum_1{$key} ) {
			$sumofLL += $tank_LLike{$key} * $tank_sensenum[$key];
		}

		if ($sumofLL >= 0) {
			$label = 1;
		}
		else {
			$label = 2;
		}
	}

	my $print_tank_sumofLL = sprintf "%0.8f", $sumofLL;

	if ($tank_sensenum[$key] == 1) {
		$tank_total_correct++;
	}
	else {
		$tank_total_incorrect++;
	}

	print "Tank correctness is: ", $tank_total_correct / ($tank_total_correct + $tank_total_incorrect), "\n";

	$tank_total_correct = 0;
	$tank_total_incorrect = 0;

	foreach $key ( keys %plant_LLike ) {
		if ( plant_sum_1{$key} ) {
			$sumofLL += $plant_LLike{$key} * $plant_sensenum[$key];
		}
	}

	if ($sumofLL >= 0) {
			$label = 1;
		}
	else {
		$label = 2;
	}
	
	my $print_plant_sumofLL = sprintf "%0.8f", $sumofLL;

	if ($label == $plant_sensenum[$key]) {
		$plant_total_correct++;
	}
	else {
		$plant_total_incorrect++;
	}
	print "plant correctness is: ", $plant_total_correct / ($plant_total_correct + $plant_total_incorrect), "\n";

	$plant_total_correct = 0;
	$plant_total_incorrect = 0;

	foreach $key ( keys %perplace_LLike ) {
		if ( perplace_sum_1{$key} ) {
			$sumofLL += $perplace_LLike{$key} * $perplace_sensenum[$key];
		}
	}

	if ($sumofLL >= 0) {
			$label = 1;
		}
	else {
		$label = 2;
	}
	
	my $print_perplace_sumofLL = sprintf "%0.8f", $sumofLL;

	if ($label == $perplace_sensenum[$key]) {
		$perplace_total_correct++;
	}
	else {
		$perplace_total_incorrect++;
	}
	print "perplace correctness is: ", $perplace_total_correct / ($perplace_total_correct + $perplace_total_incorrect), "\n";

	$perplace_total_correct = 0;
	$perplace_total_incorrect = 0;
}

sub evaluation {

	print "\n\n";

	print "\t***************************************************************************************\n\n";
	print "\t---------------------------------------------------------------------------------------\n";
	printf("\t%-15s | %-15s | %-15s | %-8s | %-8s | %-8s\n", 
		"Stemming", "Weighting", "Modelling", "tank", "plant", "pers/place"
	);
	print "\t---------------------------------------------------------------------------------------\n";
	&variation_model("unstemmed",	"uniform", "one");
	&variation_model("stemmed",		"expndecay", "one");
	&variation_model("unstemmed",	"expndecay", "one");
	&variation_model("unstemmed",	"expndecay", "LR");
	&variation_model("unstemmed",	"stepped", "LR");
	&variation_model("unstemmed",	"yours", "LR");
	for (my $index = 0; $index < @result_array; $index++) {
			printf("\t%-15s | %-15s | %-15s | %-8.4f | %-8.4f | %-8.4f\n", @result_array
		);
	}


	print "\t---------------------------------------------------------------------------------------\n";
	print "\n\t***************************************************************************************\n";

}

sub variation_model {

	my $tank = 0;
	my $plant = 0;
	my $perplace = 0;

	&init("tank", $_[0], "stopwords", $_[1], $_[2]);
	&init_average();
	$tank = &evaluation_similarity();
	
	&init("plant", $_[0], "stopwords", $_[1], $_[2]);
	&init_average();
	$plant = &evaluation_similarity();
	
	&init("perplace", $_[0], "stopwords", $_[1], $_[2]);
	&init_average();
	$perplace = &evaluation_similarity();
	
	my $stem;

	if ($_[0] eq "stemmed") {
		$stem = "stemmed";
	}
	else {
		$stem = "unstemmed";
	}
	
	my $weight;

	if ($_[1] eq "uniform") {
		$weight = "#0-uniform";
	}
	elsif ($_[1] eq "expndecay") {
		$weight = "#1-expndecay";
	}
	elsif ($_[1] eq "stepped") {
		$weight = "#2-stepped";
	}
	else {
		$weight = "#3-yours";
	}
	
	my $model;

	if ($_[2] eq "one") {
		$model = "#1-bag-words";
	}
	else {
		$model = "#2-adj-sep-LR";
	}
	printf("\t%-15s | %-15s | %-15s | %-8.4f | %-8.4f | %-8.4f\n", 
		$stem, $weight, $model, $tank, $plant, $perplace
	);
}

sub cosine_sim_a {

    my $vec1 = shift;
    my $vec2 = shift;

    my $num     = 0;
    my $sum_sq1 = 0;
    my $sum_sq2 = 0;

    my @val1 = values %{ $vec1 };
    my @val2 = values %{ $vec2 };

    # determine shortest length vector. This should speed 
    # things up if one vector is considerable longer than
    # the other (i.e. query vector to document vector).

    if ((scalar @val1) > (scalar @val2)) {
		my $tmp  = $vec1;
	    $vec1 = $vec2;
	    $vec2 = $tmp;
    }

    # calculate the cross product

    my $key = undef;
    my $val = undef;

    while (($key, $val) = each %{ $vec1 }) {
		$num += $val * ($$vec2{ $key } || 0);
    }

    # calculate the sum of squares

    my $term = undef;

    foreach $term (@val1) { $sum_sq1 += $term * $term; }
    foreach $term (@val2) { $sum_sq2 += $term * $term; }

	if ($sum_sq1 * $sum_sq2 eq 0) { return 0; }
	else {
		return ( $num / sqrt( $sum_sq1 * $sum_sq2 ));
	}
}

sub init_average {

	@doc_average_1 = ();
	@doc_average_2 = ();
	push @doc_average_1, {};
	push @doc_average_2, {};

	my $i = 0;
	my $key = undef;

	for ($i= 1; $i <= $num_doc_train; $i++) {
		if ($doc_type[$i] == 1) {
			foreach $key (keys % {$doc_weight[$i]}) {
				$doc_average_1[0]{$key} += $doc_weight[$i]{$key};
			}
		}
		else {
			foreach $key (keys % {$doc_weight[$i]}) {
				$doc_average_2[0]{$key} += $doc_weight[$i]{$key};
			}
		}
	}
	foreach $key (keys % {$doc_average_1[0]}) {
		$doc_average_1[0]{$key} /= $num_doc_1;
	}
	foreach $key (keys % {$doc_average_2[0]}) {
		$doc_average_2[0]{$key} /= $num_doc_2;
	}

}

sub evaluation_similarity {

	my $result = 0;
	my $i = 0;
	for ($i= $num_doc_train+1; $i <= $num_doc_total; $i++) {
		if(&cosine_sim_a($doc_average_1[0], $doc_weight[$i]) > 
			&cosine_sim_a($doc_average_2[0], $doc_weight[$i])) {
			if ($doc_type[$i] == 1) {
				$result ++;
			}
		}
		else {
			if ($doc_type[$i] == 2) {
				$result ++;
			}
		}
	}
	return $result / $num_doc_test;

}



